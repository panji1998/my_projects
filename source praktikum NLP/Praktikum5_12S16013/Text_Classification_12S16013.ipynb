{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memeriksa library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 0.20.3\n",
      "numpy version: 1.16.2\n",
      "nltk version: 3.4\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"scikit-learn version: {}\".format(sklearn.__version__))\n",
    "\n",
    "import numpy\n",
    "print(\"numpy version: {}\".format(numpy.__version__))\n",
    "\n",
    "import nltk\n",
    "print(\"nltk version: {}\".format(nltk.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latihan 1 | Load Data and Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = load_files(\"D:/document/semester 7/NLP/Praktikum/prak5/20news-bydate-train\", categories=categories, load_content=True, shuffle=True, encoding='latin1', decode_error='strict', random_state=42)\n",
    "twenty_test = load_files(\"D:/document/semester 7/NLP/Praktikum/prak5/20news-bydate-test\", categories=categories, load_content=True, shuffle=True, encoding='latin1', decode_error='strict', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3759\n"
     ]
    }
   ],
   "source": [
    "print (len(twenty_train.data) + len(twenty_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: clipper@mccarthy.csd.uwo.ca (Khun Yee Fung)\n",
      "Subject: Re: looking for circle algorithm faster than Bresenhams\n",
      "Organization: Department of Computer Science, The University of Western\n",
      "\tOntario, London, Ontario, Canada\n",
      "In-Reply-To: graeme@labtam.labtam.oz.au's message of Wed, 14 Apr 1993 04:49:46 GMT\n",
      "\t<1993Apr13.025240.8884@nwnexus.WA.COM>\n",
      "\t<1993Apr14.044946.12144@labtam.labtam.oz.au>\n",
      "Nntp-Posting-Host: mccarthy.csd.uwo.ca\n",
      "Lines: 41\n",
      "\n",
      ">>>>> On Wed, 14 Apr 1993 04:49:46 GMT, graeme@labtam.labtam.oz.au (Graeme Gill) said:\n",
      "\n",
      "Graeme> \tYes, that's known as \"Bresenhams Run Length Slice Algorithm for\n",
      "Graeme> Incremental lines\". See Fundamental Algorithms for Computer Graphics,\n",
      "Graeme> Springer-Verlag, Berlin Heidelberg 1985.\n",
      "\n",
      "> I have tried to extrapolate this to circles but I can't figure out\n",
      "> how to determine the length of the slices. Any ideas?\n",
      "\n",
      "Graeme> \tHmm. I don't think I can help you with this, but you might\n",
      "Graeme> take a look at the following:\n",
      "\n",
      "Graeme> \t\"Double-Step Incremental Generation of Lines and Circles\",\n",
      "Graeme> X. Wu and J. G. Rokne, Computer Graphics and Image processing,\n",
      "Graeme> Vol 37, No. 4, Mar. 1987, pp. 331-334\n",
      "\n",
      "Graeme> \t\"Double-Step Generation of Ellipses\", X. Wu and J. G. Rokne,\n",
      "Graeme> IEEE Computer Graphics & Applications, May 1989, pp. 56-69\n",
      "\n",
      "Another paper you might want to consider is:\n",
      "\n",
      "@article{fungdraw,\n",
      "  title=\"A Run-Length Slice Line Drawing Algorithm without Division Operations\",\n",
      "  author=\"Khun Yee Fung and Tina M. Nicholl and A. K. Dewdney\",\n",
      "  journal=\"Computer Graphics Forum\",\n",
      "  year=1992,\n",
      "  volume=11,\n",
      "  number=3,\n",
      "  pages=\"C-267--C-277\"\n",
      "}\n",
      "\n",
      "Khun Yee\n",
      "--\n",
      "Khun Yee Fung    clipper@csd.uwo.ca\n",
      "Department of Computer Science\n",
      "Middlesex College\n",
      "University of Western Ontario\n",
      "London, Ontario\n",
      "Canada N6A 5B7\n",
      "Tel: (519) 661-6889\n",
      "Fax: (519) 661-3515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings = list(range(len(twenty_train.target_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dic = dict(zip(codings, twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(target_dic[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latihan 2| Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from:\n",
      "clipper@mccarthy.csd.uwo.ca\n",
      "(khun\n",
      "yee\n",
      "fung)\n",
      "subject:\n",
      "re:\n",
      "look\n",
      "for\n",
      "circl\n",
      "algorithm\n",
      "faster\n",
      "than\n",
      "bresenham\n",
      "organization:\n",
      "depart\n",
      "of\n",
      "comput\n",
      "science,\n",
      "the\n",
      "univers\n",
      "of\n",
      "western\n",
      "ontario,\n",
      "london,\n",
      "ontario,\n",
      "canada\n",
      "in-reply-to:\n",
      "graeme@labtam.labtam.oz.au'\n",
      "messag\n",
      "of\n",
      "wed,\n",
      "14\n",
      "apr\n",
      "1993\n",
      "04:49:46\n",
      "gmt\n",
      "<1993apr13.025240.8884@nwnexus.wa.com>\n",
      "<1993apr14.044946.12144@labtam.labtam.oz.au>\n",
      "nntp-posting-host:\n",
      "mccarthy.csd.uwo.ca\n",
      "lines:\n",
      "41\n",
      ">>>>>\n",
      "On\n",
      "wed,\n",
      "14\n",
      "apr\n",
      "1993\n",
      "04:49:46\n",
      "gmt,\n",
      "graeme@labtam.labtam.oz.au\n",
      "(graem\n",
      "gill)\n",
      "said:\n",
      "graeme>\n",
      "yes,\n",
      "that'\n",
      "known\n",
      "as\n",
      "\"bresenham\n",
      "run\n",
      "length\n",
      "slice\n",
      "algorithm\n",
      "for\n",
      "graeme>\n",
      "increment\n",
      "lines\".\n",
      "see\n",
      "fundament\n",
      "algorithm\n",
      "for\n",
      "comput\n",
      "graphics,\n",
      "graeme>\n",
      "springer-verlag,\n",
      "berlin\n",
      "heidelberg\n",
      "1985.\n",
      ">\n",
      "I\n",
      "have\n",
      "tri\n",
      "to\n",
      "extrapol\n",
      "thi\n",
      "to\n",
      "circl\n",
      "but\n",
      "I\n",
      "can't\n",
      "figur\n",
      "out\n",
      ">\n",
      "how\n",
      "to\n",
      "determin\n",
      "the\n",
      "length\n",
      "of\n",
      "the\n",
      "slices.\n",
      "ani\n",
      "ideas?\n",
      "graeme>\n",
      "hmm.\n",
      "I\n",
      "don't\n",
      "think\n",
      "I\n",
      "can\n",
      "help\n",
      "you\n",
      "with\n",
      "this,\n",
      "but\n",
      "you\n",
      "might\n",
      "graeme>\n",
      "take\n",
      "a\n",
      "look\n",
      "at\n",
      "the\n",
      "following:\n",
      "graeme>\n",
      "\"double-step\n",
      "increment\n",
      "gener\n",
      "of\n",
      "line\n",
      "and\n",
      "circles\",\n",
      "graeme>\n",
      "X.\n",
      "Wu\n",
      "and\n",
      "J.\n",
      "G.\n",
      "rokne,\n",
      "comput\n",
      "graphic\n",
      "and\n",
      "imag\n",
      "processing,\n",
      "graeme>\n",
      "vol\n",
      "37,\n",
      "no.\n",
      "4,\n",
      "mar.\n",
      "1987,\n",
      "pp.\n",
      "331-334\n",
      "graeme>\n",
      "\"double-step\n",
      "gener\n",
      "of\n",
      "ellipses\",\n",
      "X.\n",
      "Wu\n",
      "and\n",
      "J.\n",
      "G.\n",
      "rokne,\n",
      "graeme>\n",
      "ieee\n",
      "comput\n",
      "graphic\n",
      "&\n",
      "applications,\n",
      "may\n",
      "1989,\n",
      "pp.\n",
      "56-69\n",
      "anoth\n",
      "paper\n",
      "you\n",
      "might\n",
      "want\n",
      "to\n",
      "consid\n",
      "is:\n",
      "@article{fungdraw,\n",
      "title=\"a\n",
      "run-length\n",
      "slice\n",
      "line\n",
      "draw\n",
      "algorithm\n",
      "without\n",
      "divis\n",
      "operations\",\n",
      "author=\"khun\n",
      "yee\n",
      "fung\n",
      "and\n",
      "tina\n",
      "M.\n",
      "nichol\n",
      "and\n",
      "A.\n",
      "K.\n",
      "dewdney\",\n",
      "journal=\"comput\n",
      "graphic\n",
      "forum\",\n",
      "year=1992,\n",
      "volume=11,\n",
      "number=3,\n",
      "pages=\"c-267--c-277\"\n",
      "}\n",
      "khun\n",
      "yee\n",
      "--\n",
      "khun\n",
      "yee\n",
      "fung\n",
      "clipper@csd.uwo.ca\n",
      "depart\n",
      "of\n",
      "comput\n",
      "scienc\n",
      "middlesex\n",
      "colleg\n",
      "univers\n",
      "of\n",
      "western\n",
      "ontario\n",
      "london,\n",
      "ontario\n",
      "canada\n",
      "n6a\n",
      "5b7\n",
      "tel:\n",
      "(519)\n",
      "661-6889\n",
      "fax:\n",
      "(519)\n",
      "661-3515\n"
     ]
    }
   ],
   "source": [
    "#Latihan 2.1 | Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "words = twenty_train.data[0].split()\n",
    "ps = PorterStemmer()\n",
    "for w in words:\n",
    "    roodword = ps.stem(w)\n",
    "    print(roodword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['661-3515']\n"
     ]
    }
   ],
   "source": [
    "#Latihan 2.2 | Lemmatization\n",
    "\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "tokenization = nltk.word_tokenize(roodword)\n",
    "for w in tokenization:\n",
    "    print (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of term-frequency matrix:   (0, 2044)\t1\n",
      "  (0, 14085)\t1\n",
      "  (0, 2775)\t1\n",
      "  (0, 2723)\t2\n",
      "  (0, 2427)\t2\n",
      "  (0, 31915)\t1\n",
      "  (0, 2562)\t1\n",
      "  (0, 22588)\t1\n",
      "  (0, 9027)\t1\n",
      "  (0, 21716)\t1\n",
      "  (0, 1723)\t1\n",
      "  (0, 1690)\t1\n",
      "  (0, 24293)\t1\n",
      "  (0, 23363)\t1\n",
      "  (0, 336)\t1\n",
      "  (0, 34481)\t1\n",
      "  (0, 1101)\t1\n",
      "  (0, 35584)\t1\n",
      "  (0, 14716)\t1\n",
      "  (0, 18942)\t1\n",
      "  (0, 11396)\t1\n",
      "  (0, 23019)\t1\n",
      "  (0, 32439)\t1\n",
      "  (0, 5862)\t1\n",
      "  (0, 23804)\t1\n",
      "  :\t:\n",
      "  (2256, 27692)\t1\n",
      "  (2256, 11687)\t1\n",
      "  (2256, 33081)\t1\n",
      "  (2256, 28058)\t2\n",
      "  (2256, 17180)\t4\n",
      "  (2256, 34741)\t2\n",
      "  (2256, 28062)\t1\n",
      "  (2256, 23250)\t1\n",
      "  (2256, 32295)\t1\n",
      "  (2256, 22541)\t1\n",
      "  (2256, 20470)\t1\n",
      "  (2256, 32270)\t1\n",
      "  (2256, 23733)\t1\n",
      "  (2256, 20253)\t1\n",
      "  (2256, 16881)\t1\n",
      "  (2256, 25663)\t2\n",
      "  (2256, 23122)\t1\n",
      "  (2256, 9072)\t2\n",
      "  (2256, 32493)\t1\n",
      "  (2256, 32142)\t2\n",
      "  (2256, 23610)\t1\n",
      "  (2256, 23915)\t1\n",
      "  (2256, 27031)\t1\n",
      "  (2256, 31077)\t1\n",
      "  (2256, 14887)\t1\n"
     ]
    }
   ],
   "source": [
    "#Latihan 2.3 | Feature Extraction\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_tf = count_vect.fit_transform(twenty_train.data)\n",
    "print(\"Shape of term-frequency matrix:\", X_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training documents: 2257\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of training documents:\", len(twenty_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of term frequency-inverse document frequency matrix: (2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_tf)\n",
    "print(\"Shape of term frequency-inverse document frequency matrix:\", X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "#Latihan 3 | A Basic Naive Bayes Model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mod = MultinomialNB()\n",
    "mod.fit(X_train_tfidf, twenty_train.target)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tf = count_vect.transform(twenty_test.data)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_tf)\n",
    "\n",
    "predicted = mod.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8348868175765646\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.60      0.74       319\n",
      "         comp.graphics       0.96      0.89      0.92       389\n",
      "               sci.med       0.97      0.81      0.88       396\n",
      "soc.religion.christian       0.65      0.99      0.78       398\n",
      "\n",
      "             micro avg       0.83      0.83      0.83      1502\n",
      "             macro avg       0.89      0.82      0.83      1502\n",
      "          weighted avg       0.88      0.83      0.84      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(twenty_test.target,\n",
    "                           predicted,\n",
    "                           target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latihan 4 | Scikit-learn Pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8348868175765646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('model', MultinomialNB()),])\n",
    "mod = pipe.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "predicted = mod.predict(twenty_test.data)\n",
    "print(\"accuracy:\", accuracy_score(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.72      0.83       319\n",
      "         comp.graphics       0.95      0.95      0.95       389\n",
      "               sci.med       0.95      0.88      0.92       396\n",
      "soc.religion.christian       0.76      0.97      0.85       398\n",
      "\n",
      "             micro avg       0.89      0.89      0.89      1502\n",
      "             macro avg       0.91      0.88      0.89      1502\n",
      "          weighted avg       0.90      0.89      0.89      1502\n",
      "\n",
      "Accuracy: 0.8894806924101198\n"
     ]
    }
   ],
   "source": [
    "#Latihan 5 | An Improved Naive Bayes Model\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('model', MultinomialNB()),])\n",
    "\n",
    "mod = pipe.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "predicted = mod.predict(twenty_test.data)\n",
    "\n",
    "print(classification_report(twenty_test.target,\n",
    "                           predicted,\n",
    "                           target_names = twenty_test.target_names))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Average Precision: 0.9079419539278434\n",
      "Micro Average Precision: 0.8894806924101198\n",
      "Weighted Average Precision: 0.9045424092926376\n"
     ]
    }
   ],
   "source": [
    "#Latihan 6 | Performance Evaluation\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "y_true = twenty_test.target\n",
    "y_pred = predicted\n",
    "\n",
    "print(\"Macro Average Precision:\",precision_score(y_true,y_pred, average='macro'))\n",
    "print(\"Micro Average Precision:\",precision_score(y_true,y_pred, average='micro'))\n",
    "print(\"Weighted Average Precision:\",precision_score(y_true,y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Average Recall: 0.8815852145928588\n",
      "Micro Average Recall: 0.8894806924101198\n",
      "Weighted Average Recall: 0.8894806924101198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_true = twenty_test.target\n",
    "y_pred = predicted\n",
    "\n",
    "print(\"Macro Average Recall:\",recall_score(y_true,y_pred, average='macro'))\n",
    "print(\"Micro Average Recall:\",recall_score(y_true,y_pred, average='micro'))\n",
    "print(\"Weighted Average Recall:\",recall_score(y_true,y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Average f1_score: 0.8867616617107978\n",
      "Micro Average f1_score: 0.8894806924101198\n",
      "Weighted Average f1_score: 0.8894459785761988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = twenty_test.target\n",
    "y_pred = predicted\n",
    "\n",
    "print(\"Macro Average f1_score:\",f1_score(y_true,y_pred, average='macro'))\n",
    "print(\"Micro Average f1_score:\",f1_score(y_true,y_pred, average='micro'))\n",
    "print(\"Weighted Average f1_score:\",f1_score(y_true,y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
