{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone\n",
      "0    1/5/2015  289        2776.0            0.0            10030.0\n",
      "1    1/4/2015  288        2775.0            0.0             9780.0\n",
      "2    1/3/2015  287        2769.0         8166.0             9722.0\n",
      "3    1/2/2015  286           0.0         8157.0                0.0\n",
      "4  12/31/2014  284        2730.0         8115.0             9633.0\n",
      "5  12/28/2014  281        2706.0         8018.0             9446.0\n",
      "6  12/27/2014  280        2695.0            0.0             9409.0\n",
      "7  12/24/2014  277        2630.0         7977.0             9203.0\n",
      "8  12/21/2014  273        2597.0            0.0             9004.0\n",
      "9  12/20/2014  272        2571.0         7862.0             8939.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ebola = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/country_timeseries.csv')\n",
    "print(ebola.fillna(0).iloc[0:10, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone\n",
      "0    1/5/2015  289        2776.0            NaN            10030.0\n",
      "1    1/4/2015  288        2775.0            NaN             9780.0\n",
      "2    1/3/2015  287        2769.0         8166.0             9722.0\n",
      "3    1/2/2015  286        2769.0         8157.0             9722.0\n",
      "4  12/31/2014  284        2730.0         8115.0             9633.0\n",
      "5  12/28/2014  281        2706.0         8018.0             9446.0\n",
      "6  12/27/2014  280        2695.0         8018.0             9409.0\n",
      "7  12/24/2014  277        2630.0         7977.0             9203.0\n",
      "8  12/21/2014  273        2597.0         7977.0             9004.0\n",
      "9  12/20/2014  272        2571.0         7862.0             8939.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.fillna(method='ffill').iloc[0:10, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone\n",
      "117  3/27/2014    5         103.0            8.0                6.0\n",
      "118  3/26/2014    4          86.0            NaN                NaN\n",
      "119  3/25/2014    3          86.0            NaN                NaN\n",
      "120  3/24/2014    2          86.0            NaN                NaN\n",
      "121  3/22/2014    0          49.0            NaN                NaN\n"
     ]
    }
   ],
   "source": [
    "print(ebola.fillna(method='bfill').iloc[:, 0:5].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone\n",
      "0    1/5/2015  289        2776.0            NaN            10030.0\n",
      "1    1/4/2015  288        2775.0            NaN             9780.0\n",
      "2    1/3/2015  287        2769.0         8166.0             9722.0\n",
      "3    1/2/2015  286        2749.5         8157.0             9677.5\n",
      "4  12/31/2014  284        2730.0         8115.0             9633.0\n",
      "5  12/28/2014  281        2706.0         8018.0             9446.0\n",
      "6  12/27/2014  280        2695.0         7997.5             9409.0\n",
      "7  12/24/2014  277        2630.0         7977.0             9203.0\n",
      "8  12/21/2014  273        2597.0         7919.5             9004.0\n",
      "9  12/20/2014  272        2571.0         7862.0             8939.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.interpolate().iloc[0:10, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 18)\n"
     ]
    }
   ],
   "source": [
    "print(ebola.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 18)\n"
     ]
    }
   ],
   "source": [
    "ebola_dropna = ebola.dropna()\n",
    "print(ebola_dropna.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone  \\\n",
      "19  11/18/2014  241        2047.0         7082.0             6190.0   \n",
      "\n",
      "    Cases_Nigeria  Cases_Senegal  Cases_UnitedStates  Cases_Spain  Cases_Mali  \\\n",
      "19           20.0            1.0                 4.0          1.0         6.0   \n",
      "\n",
      "    Deaths_Guinea  Deaths_Liberia  Deaths_SierraLeone  Deaths_Nigeria  \\\n",
      "19         1214.0          2963.0              1267.0             8.0   \n",
      "\n",
      "    Deaths_Senegal  Deaths_UnitedStates  Deaths_Spain  Deaths_Mali  \n",
      "19             0.0                  1.0           0.0          6.0  \n"
     ]
    }
   ],
   "source": [
    "print(ebola_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "array = [ 4, 8, 9, 15, 21, 21, 24, 25, 26, 28, 29, 34] \n",
    "sa = np.sort(array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_mean = np.zeros((3,4))\n",
    "bin_boundaries = np.zeros ((3,4))\n",
    "bin_median = np.zeros((3,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Mean: \n",
      " [[ 9.    9.    9.    9.  ]\n",
      " [22.75 22.75 22.75 22.75]\n",
      " [29.25 29.25 29.25 29.25]]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,12,4):\n",
    "    k = int(i/4)\n",
    "    mean = (sa[i] + sa[i+1] + sa[i+2] + sa[i+3])/4\n",
    "    for j in range(4):\n",
    "        bin_mean[k,j] = mean\n",
    "print(\"Bin Mean: \\n\", bin_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Boundaries: \n",
      " [[ 4.  4.  4. 15.]\n",
      " [21. 21. 25. 25.]\n",
      " [26. 26. 26. 34.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,12,4):\n",
    "    k = int(i/4)\n",
    "    for j in range(4):\n",
    "        if (sa[i+j]-sa[i]) < (sa[i+3]-sa[i+j]):\n",
    "                bin_boundaries[k,j] = sa[i]\n",
    "        else:\n",
    "            bin_boundaries[k,j] = sa[i+3]\n",
    "print(\"Bin Boundaries: \\n\", bin_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Median: \n",
      " [[ 9.  9.  9.  9.]\n",
      " [24. 24. 24. 24.]\n",
      " [29. 29. 29. 29.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,12,4):\n",
    "    k = int(i/4)\n",
    "    for j in range(4):\n",
    "        bin_median[k,j] = sa[i+2]\n",
    "print(\"Bin Median: \\n\", bin_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/concat_1.csv')\n",
    "df2 = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/concat_2.csv')\n",
    "df3 = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/concat_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat = pd.concat([df1, df2, df3])\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    a3\n",
      "B    b3\n",
      "C    c3\n",
      "D    d3\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(row_concat.iloc[3, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    n1\n",
      "1    n2\n",
      "2    n3\n",
      "3    n4\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "new_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\n",
    "print(new_row_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, new_row_series]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "new_row_df = pd.DataFrame([['n1', 'n2', 'n3', 'n4']], columns=['A', 'B', 'C', 'D'])\n",
    "print(new_row_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, new_row_df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n"
     ]
    }
   ],
   "source": [
    "print(df1.append(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "print(df1.append(new_row_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "4  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'A': 'n1',\n",
    "            'B': 'n2',\n",
    "            'C': 'n3',\n",
    "            'D': 'n4'}\n",
    "\n",
    "print(df1.append(data_dict, ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat_i = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "print(row_concat_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   A    A\n",
      "0  a0  a4   a8\n",
      "1  a1  a5   a9\n",
      "2  a2  a6  a10\n",
      "3  a3  a7  a11\n"
     ]
    }
   ],
   "source": [
    "print(col_concat['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_list\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8           n1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9           n2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10           n3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11           n4\n"
     ]
    }
   ],
   "source": [
    "col_concat['new_col_list'] = ['n1', 'n2', 'n3', 'n4']\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_list  \\\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8           n1   \n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9           n2   \n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10           n3   \n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11           n4   \n",
      "\n",
      "  new_col_series  \n",
      "0             n1  \n",
      "1             n2  \n",
      "2             n3  \n",
      "3             n4  \n"
     ]
    }
   ],
   "source": [
    "col_concat['new_col_series'] = pd.Series(['n1', 'n2', 'n3', 'n4'])\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3   4   5   6   7    8    9    10   11\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2,df3], axis=1, ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['A', 'B', 'C', 'D']\n",
    "df2.columns = ['E', 'F', 'G', 'H']\n",
    "df3.columns = ['A', 'C', 'F', 'H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    E   F   G   H\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "0  NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "1  NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "2  NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "3  NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "0   a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "1   a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "2  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "3  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat = pd.concat([df1, df2, df3], sort=False)\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df2], join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C\n",
      "0   a0   c0\n",
      "1   a1   c1\n",
      "2   a2   c2\n",
      "3   a3   c3\n",
      "0   a8   b8\n",
      "1   a9   b9\n",
      "2  a10  b10\n",
      "3  a11  b11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df3], ignore_index=False, join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index = ['0', '1', '2', '3']\n",
    "df2.index = ['4', '5', '6', '7']\n",
    "df3.index = ['0', '2', '5', '7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "2   a9   b9   c9   d9\n",
      "5  a10  b10  c10  d10\n",
      "7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H    A    C    F    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN   a8   b8   c8   d8\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN   a9   b9   c9   d9\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4  NaN  NaN  NaN  NaN\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5  a10  b10  c10  d10\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN  NaN  NaN  NaN\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7  a11  b11  c11  d11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   C   F   H\n",
      "0  a0  b0  c0  d0  a8  b8  c8  d8\n",
      "2  a2  b2  c2  d2  a9  b9  c9  d9\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df3], axis=1, join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth\n",
      "    taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735    NaN   sal     0.06\n",
      "9     735    NaN  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25\n",
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "person = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/survey_person.csv')\n",
    "site= pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/survey_site.csv')\n",
    "survey = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/survey_survey.csv')\n",
    "visited = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/survey_visited.csv')\n",
    "\n",
    "print(person)\n",
    "print(survey)\n",
    "print(site)\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "visited_subset = visited.ix[[0, 2,6], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "o2o_merge = site.merge(visited_subset, left_on='name',right_on='site')\n",
    "print(o2o_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "m2o_merge = site.merge(visited, left_on='name',right_on='site')\n",
    "print(m2o_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   personal   family  taken person quant  reading\n",
      "0   dyer    William     Dyer    619   dyer   rad     9.82\n",
      "1   dyer    William     Dyer    619   dyer   sal     0.13\n",
      "2   dyer    William     Dyer    622   dyer   rad     7.80\n",
      "3   dyer    William     Dyer    622   dyer   sal     0.09\n",
      "4     pb      Frank  Pabodie    734     pb   rad     8.41\n",
      "5     pb      Frank  Pabodie    734     pb  temp   -21.50\n",
      "6     pb      Frank  Pabodie    735     pb   rad     7.22\n",
      "7     pb      Frank  Pabodie    751     pb   rad     4.35\n",
      "8     pb      Frank  Pabodie    751     pb  temp   -18.50\n",
      "9   lake   Anderson     Lake    734   lake   sal     0.05\n",
      "10  lake   Anderson     Lake    751   lake   sal     0.10\n",
      "11  lake   Anderson     Lake    752   lake   rad     2.19\n",
      "12  lake   Anderson     Lake    752   lake   sal     0.09\n",
      "13  lake   Anderson     Lake    752   lake  temp   -16.00\n",
      "14  lake   Anderson     Lake    837   lake   rad     1.46\n",
      "15  lake   Anderson     Lake    837   lake   sal     0.21\n",
      "16   roe  Valentina  Roerich    752    roe   sal    41.60\n",
      "17   roe  Valentina  Roerich    837    roe   sal    22.50\n",
      "18   roe  Valentina  Roerich    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "ps = person.merge(survey, left_on='ident', right_on='person')\n",
    "vs = visited.merge(survey, left_on='ident', right_on='taken')\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ident   site       dated  taken person quant  reading\n",
      "0     619   DR-1  1927-02-08    619   dyer   rad     9.82\n",
      "1     619   DR-1  1927-02-08    619   dyer   sal     0.13\n",
      "2     622   DR-1  1927-02-10    622   dyer   rad     7.80\n",
      "3     622   DR-1  1927-02-10    622   dyer   sal     0.09\n",
      "4     734   DR-3  1939-01-07    734     pb   rad     8.41\n",
      "5     734   DR-3  1939-01-07    734   lake   sal     0.05\n",
      "6     734   DR-3  1939-01-07    734     pb  temp   -21.50\n",
      "7     735   DR-3  1930-01-12    735     pb   rad     7.22\n",
      "8     735   DR-3  1930-01-12    735    NaN   sal     0.06\n",
      "9     735   DR-3  1930-01-12    735    NaN  temp   -26.00\n",
      "10    751   DR-3  1930-02-26    751     pb   rad     4.35\n",
      "11    751   DR-3  1930-02-26    751     pb  temp   -18.50\n",
      "12    751   DR-3  1930-02-26    751   lake   sal     0.10\n",
      "13    752   DR-3         NaN    752   lake   rad     2.19\n",
      "14    752   DR-3         NaN    752   lake   sal     0.09\n",
      "15    752   DR-3         NaN    752   lake  temp   -16.00\n",
      "16    752   DR-3         NaN    752    roe   sal    41.60\n",
      "17    837  MSK-4  1932-01-14    837   lake   rad     1.46\n",
      "18    837  MSK-4  1932-01-14    837   lake   sal     0.21\n",
      "19    837  MSK-4  1932-01-14    837    roe   sal    22.50\n",
      "20    844   DR-1  1932-03-22    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_vs = ps.merge(vs,\n",
    "                 left_on=['ident', 'taken', 'quant', 'reading'],\n",
    "                 right_on=['person','ident','quant', 'reading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ident_x           dyer\n",
      "personal       William\n",
      "family            Dyer\n",
      "taken_x            619\n",
      "person_x          dyer\n",
      "quant              rad\n",
      "reading           9.82\n",
      "ident_y            619\n",
      "site              DR-1\n",
      "dated       1927-02-08\n",
      "taken_y            619\n",
      "person_y          dyer\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ps_vs.loc[0, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -7.84170828 -12.59183041]\n",
      " [ -9.2638174   -1.06657762]\n",
      " [-20.96602518  -3.92729715]\n",
      " [-12.43201934 -25.18583558]\n",
      " [ 16.01355999  16.63692306]\n",
      " [ -5.13191019   2.38929446]\n",
      " [  9.33623593  -5.27897273]\n",
      " [  6.58085739 -16.319062  ]\n",
      " [ 12.23414033   0.30674688]\n",
      " [ -7.51111002   6.77052294]\n",
      " [ 36.217585    -2.34725768]\n",
      " [ 14.32048033  -9.2296796 ]\n",
      " [ -5.13301929  18.98084587]\n",
      " [ 17.49829341   5.33277962]\n",
      " [-13.78517421  20.25751047]\n",
      " [ -1.51513576  25.29789293]\n",
      " [-11.83756983   1.57183023]\n",
      " [-21.19439155  -3.83927071]\n",
      " [  4.41072868 -17.75856299]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/d_data.csv')\n",
    "\n",
    "pca = PCA(n_components=2).fit_transform(data)\n",
    "print(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1952    49.057620\n",
      "1957    51.507401\n",
      "1962    53.609249\n",
      "1967    55.678290\n",
      "1972    57.647386\n",
      "1977    59.570157\n",
      "1982    61.533197\n",
      "1987    63.212613\n",
      "1992    64.160338\n",
      "1997    65.014676\n",
      "2002    65.694923\n",
      "2007    67.007423\n",
      "Name: lifeExp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/gapminder.tsv', sep='\\t')\n",
    "\n",
    "avg_life_exp_by_year = df.groupby('year').lifeExp.mean()\n",
    "print(avg_life_exp_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_life_exp_by_year = df.groupby('year')['lifeExp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 2002 2007]\n"
     ]
    }
   ],
   "source": [
    "years = df.year.unique()\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country continent  year  lifeExp       pop    gdpPercap\n",
      "0   Afghanistan      Asia  1952   28.801   8425333   779.445314\n",
      "12      Albania    Europe  1952   55.230   1282697  1601.056136\n",
      "24      Algeria    Africa  1952   43.077   9279525  2449.008185\n",
      "36       Angola    Africa  1952   30.015   4232095  3520.610273\n",
      "48    Argentina  Americas  1952   62.485  17876956  5911.315053\n"
     ]
    }
   ],
   "source": [
    "y1952 = df.loc[df.year == 1952, :]\n",
    "print(y1952.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.05761971830987\n"
     ]
    }
   ],
   "source": [
    "y1952_mean = y1952.lifeExp.mean()\n",
    "print(y1952_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count       mean        std     min       25%      50%       75%  \\\n",
      "continent                                                                     \n",
      "Africa     624.0  48.865330   9.150210  23.599  42.37250  47.7920  54.41150   \n",
      "Americas   300.0  64.658737   9.345088  37.579  58.41000  67.0480  71.69950   \n",
      "Asia       396.0  60.064903  11.864532  28.801  51.42625  61.7915  69.50525   \n",
      "Europe     360.0  71.903686   5.433178  43.585  69.57000  72.2410  75.45050   \n",
      "Oceania     24.0  74.326208   3.795611  69.120  71.20500  73.6650  77.55250   \n",
      "\n",
      "              max  \n",
      "continent          \n",
      "Africa     76.442  \n",
      "Americas   80.653  \n",
      "Asia       82.603  \n",
      "Europe     81.757  \n",
      "Oceania    81.235  \n"
     ]
    }
   ],
   "source": [
    "continent_describe = df.groupby('continent').lifeExp.describe()\n",
    "print(continent_describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('D:/SEMESTER 7/DATA MINING/WEEK 4/praktikum/data/gapminder.tsv', sep='\\t')\n",
    "\n",
    "def my_zscore(x):\n",
    "    '''Calculates the z-score of provided data\n",
    "    'x' is a vector of series df values\n",
    "    '''\n",
    "    \n",
    "    return ((x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_z = df.groupby('year').lifeExp.transform(my_zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1704, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1704,)\n"
     ]
    }
   ],
   "source": [
    "print(transform_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "sp_z_grouped = df.groupby('year').lifeExp.transform(zscore)\n",
    "\n",
    "sp_z_nogroup = zscore(df.lifeExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1.656854\n",
      "1   -1.731249\n",
      "2   -1.786543\n",
      "3   -1.848157\n",
      "4   -1.894173\n",
      "Name: lifeExp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(transform_z.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1.662719\n",
      "1   -1.737377\n",
      "2   -1.792867\n",
      "3   -1.854699\n",
      "4   -1.900878\n",
      "Name: lifeExp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sp_z_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.37533395 -2.25677417 -2.1278375  -1.97117751 -1.81103275]\n"
     ]
    }
   ],
   "source": [
    "print(sp_z_nogroup[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
